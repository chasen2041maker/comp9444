import json, os, shutil, random
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader
from torchvision import transforms, datasets, models
import matplotlib.pyplot as plt
import sklearn.metrics as metrics
from PIL import Image


def preprocess_dataset(categories):
    # Classify the AAT dataset.
    classified_image_paths = {}
    for category in categories:
        classified_image_paths[category] = []
    with open('【AiDLab】A100/AAT/label/AAT.json') as file:
        content = file.read()
    ls = []
    for dic in json.loads(content):
        ls.extend(dic['answers'])
        ls.extend(dic['question'])
    for s in ls:
        image_path = s[-6:] + '.jpg'
        match s[0]:
            case 'S':
                classified_image_paths['shoes'].append(image_path)
            case 'C':
                classified_image_paths['clothing'].append(image_path)
            case 'A':
                classified_image_paths['accessories'].append(image_path)
            case 'B':
                classified_image_paths['bags'].append(image_path)
    # Split the AAT dataset.
    for category in categories:
        image_paths = classified_image_paths[category]
        random.shuffle(image_paths)
        splitted_image_paths = {
            'train': image_paths[:int(0.6 * len(image_paths))],
            'validate': image_paths[int(0.6 * len(image_paths)):int(0.8 * len(image_paths))],
            'test': image_paths[int(0.8 * len(image_paths)):]
        }
        for phase, image_paths in splitted_image_paths.items():
            os.makedirs(os.path.join('dataset', phase, category), exist_ok=True)
            for image_path in image_paths:
                source = os.path.join('【AiDLab】A100/AAT/image', image_path)
                destination = os.path.join('dataset', phase, category, image_path)
                shutil.copyfile(source, destination)


def train_and_validate(device, model, train_loader, validate_loader, criterion, optimizer, scheduler, epochs):
    train_losses, train_accuracies = [], []
    validate_losses, validate_accuracies = [], []
    print('Training and validation start.')
    best_validate_loss = float('inf')
    patience_counter = 0
    for epoch in range(epochs):
        print(f'Epoch {epoch + 1}/{epochs}')
        # Train the network.
        model.train()
        running_loss = 0
        correct = 0
        total = 0
        for inputs, labels in train_loader:
            inputs, labels = inputs.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(inputs)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            running_loss += loss.item() * inputs.size(0)
            _, predictions = torch.max(outputs.data, 1)
            correct += (predictions == labels).sum().item()
            total += labels.size(0)
        train_loss = running_loss / total
        train_losses.append(train_loss)
        train_accuracy = correct / total
        train_accuracies.append(train_accuracy)
        print(f'\tTraining loss: {train_loss:.4f}\tTraining accuracy: {train_accuracy:.4f}')
        # Validate the network.
        model.eval()
        running_loss = 0
        correct = 0
        total = 0
        with torch.no_grad():
            for inputs, labels in validate_loader:
                inputs, labels = inputs.to(device), labels.to(device)
                outputs = model(inputs)
                loss = criterion(outputs, labels)
                running_loss += loss.item() * inputs.size(0)
                _, predictions = torch.max(outputs.data, 1)
                correct += (predictions == labels).sum().item()
                total += labels.size(0)
        validate_loss = running_loss / total
        validate_losses.append(validate_loss)
        validate_accuracy = correct / total
        validate_accuracies.append(validate_accuracy)
        print(f'\tValidation loss: {validate_loss:.4f}\tValidation accuracy: {validate_accuracy:.4f}')
        # Check the early stopping.
        if validate_loss < best_validate_loss:
            patience_counter = 0
            best_validate_loss = validate_loss
            # Save the model.
            torch.save(model.state_dict(), 'model.pth')
        else:
            patience_counter += 1
            if patience_counter == 10:
                break
    print('Training and validation end.')
    return train_losses, validate_losses, train_accuracies, validate_accuracies


def test(device, model, test_loader, criterion, categories):
    cm_labels = []
    cm_predictions = []
    print('Test starts.')
    model.eval()
    with torch.no_grad():
        for inputs, labels in test_loader:
            inputs, labels = inputs.to(device), labels.to(device)
            outputs = model(inputs)
            _, predictions = torch.max(outputs.data, 1)
            cm_labels.extend(labels.cpu().numpy())
            cm_predictions.extend(predictions.cpu().numpy())
    print(metrics.classification_report(cm_labels, cm_predictions, target_names=categories))
    print('Test ends.')
    return cm_labels, cm_predictions


def plot_loss(epochs, train_losses, validate_losses):
    plt.figure()
    plt.plot(epochs, train_losses, label='Training Loss')
    plt.plot(epochs, validate_losses, label='Validation Loss')
    plt.title('Loss Curves')
    plt.xlabel('Epoch')
    plt.ylabel('Loss')
    plt.legend()
    plt.savefig('loss.png')
    plt.show()


def plot_accuracy(epochs, train_accuracies, validate_accuracies):
    plt.figure()
    plt.plot(epochs, train_accuracies, label='Training Accuracy')
    plt.plot(epochs, validate_accuracies, label='Validation Accuracy')
    plt.title('Accuracy Curves')
    plt.xlabel('Epoch')
    plt.ylabel('Accuracy')
    plt.legend()
    plt.savefig('accuracy.png')
    plt.show()


def plot_confusion_matrix(cm_labels, cm_predictions, categories):
    plt.figure()
    cm = metrics.confusion_matrix(cm_labels, cm_predictions)
    metrics.ConfusionMatrixDisplay(cm, display_labels=categories).plot()
    plt.title('Confusion Matrix')
    plt.savefig('confusion_matrix.png')
    plt.show()


def test_arbitrary(device, model, categories):
    # Classify the LAT dataset.
    classified_dataset = {}
    for category in categories:
        classified_dataset[category] = []
    with open('【AiDLab】A100/LAT/label/LAT.json') as file:
        content = file.read()
    ls = []
    for dic in json.loads(content):
        ls.extend(dic['answers'])
        ls.extend(dic['question'])
    image_paths = []
    for s in ls:
        image_path = s[-9:] + '.jpg'
        image_paths.append(os.path.join('【AiDLab】A100/LAT/image', image_path))
        match s[0:2]:
            case 'Sh':
                classified_dataset['shoes'].append(image_path)
            case 'Pa' | 'Ou' | 'To' | 'Sk' | 'Dr':
                classified_dataset['clothing'].append(image_path)
            case 'Ea' | 'Wa' | 'Br' | 'Ne' | 'Ha' | 'Su':
                classified_dataset['accessories'].append(image_path)
            case 'Ba':
                classified_dataset['bags'].append(image_path)
    # Define the transformation.
    transform = transforms.Compose([
        transforms.Resize(size=224),
        transforms.CenterCrop(size=224),
        transforms.ToTensor(),
        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
    ])
    # Load a random data point from the dataset.
    pt = random.choice(image_paths)
    image = Image.open(pt)
    for k, v in classified_dataset.items():
        if pt[-13:] in v:
          print(k)
          break
    plt.figure()
    plt.imshow(image)
    plt.axis('off')
    plt.savefig('test.jpg')
    plt.show()
    inputs = transform(image.convert('RGB')).unsqueeze(0)
    inputs = inputs.to(device)
    # Test the network.
    model.eval()
    with torch.no_grad():
        outputs = model(inputs)
        _, predictions = torch.max(outputs.data, 1)
    predicted_category = categories[predictions.item()]
    print(f'Predicted category: {predicted_category}')


def main():
    # Define the categories.
    categories = ['shoes', 'clothing', 'accessories', 'bags']
    # Preprocess the dataset.
    if not os.path.exists('dataset'): preprocess_dataset(categories)
    # Define the transformation.
    transform = {
        'train': transforms.Compose([
            transforms.RandomResizedCrop(size=224, scale=(0.8, 1.0)),
            transforms.RandomRotation(degrees=15),
            transforms.RandomHorizontalFlip(),
            transforms.CenterCrop(size=224),
            transforms.ToTensor(),
            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
        ]),
        'validate': transforms.Compose([
            transforms.Resize(size=224),
            transforms.CenterCrop(size=224),
            transforms.ToTensor(),
            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
        ]),
        'test': transforms.Compose([
            transforms.Resize(size=224),
            transforms.CenterCrop(size=224),
            transforms.ToTensor(),
            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
        ])
    }
    # Load the dataset.
    dataset = {
        'train': datasets.ImageFolder(root='dataset/train', transform=transform['train']),
        'validate': datasets.ImageFolder(root='dataset/validate', transform=transform['validate']),
        'test': datasets.ImageFolder(root='dataset/test', transform=transform['test'])
    }
    # Define the data loaders.
    batch_size = 64
    train_loader = DataLoader(dataset['train'], batch_size=batch_size, shuffle=True)
    validate_loader = DataLoader(dataset['validate'], batch_size=batch_size, shuffle=False)
    test_loader = DataLoader(dataset['test'], batch_size=batch_size, shuffle=False)
    # Set the device.
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    # Load the MobileNetV2 model.
    model = models.mobilenet_v2(pretrained=True)
    model.classifier[1] = nn.Sequential(
        nn.Dropout(0.5),
        nn.Linear(model.last_channel, len(categories))
    )
    model = model.to(device)
    if os.path.exists('model.pth'): model.load_state_dict(torch.load('model.pth'))
    # Define the loss function.
    criterion = nn.CrossEntropyLoss()
    # Define the optimizer.
    learning_rate = 0.0001
    optimizer = optim.Adam(model.parameters(), lr=learning_rate)
    # Define the learning rate scheduler.
    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=5, verbose=True)
    # Run the network and plot the charts.
    if not os.path.exists('model.pth'):
        # Train and validate the network.
        epochs = 50
        train_losses, validate_losses, train_accuracies, validate_accuracies = train_and_validate(device, model, train_loader, validate_loader, criterion, optimizer, scheduler, epochs)
        # Plot the loss curves.
        plot_loss(range(1, len(train_losses) + 1), train_losses, validate_losses)
        # Plot the accuracy curves.
        plot_accuracy(range(1, len(train_accuracies) + 1), train_accuracies, validate_accuracies)
    # Test the network.
    cm_labels, cm_predictions = test(device, model, test_loader, criterion, categories)
    # Plot the confusion matrix.
    plot_confusion_matrix(cm_labels, cm_predictions, categories)
    # Test an arbitrary image.
    test_arbitrary(device, model, categories)


if __name__ == '__main__':
    main()
