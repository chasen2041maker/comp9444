{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "debc67b2-7b18-4afd-bcea-6c9ba1e0e877",
   "metadata": {},
   "source": [
    "按顺序提取json文件中的answers和question标签，并且直接输出 answers 和 question 的内容"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be14fd4f-4abd-41b4-93d7-901063e27599",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# 文件路径列表\n",
    "file_paths = [\n",
    "    (\"AAT.json\", r\"./【AiDLab】A100/AAT/label/AAT.json\"),\n",
    "    (\"LAT.json\", r\"./【AiDLab】A100/LAT/label/LAT.json\")\n",
    "]\n",
    "\n",
    "# 用于存储所有的 answers 和 questions\n",
    "all_answers = []\n",
    "all_questions = []\n",
    "\n",
    "# 遍历文件路径，加载并提取每个文件中的标签\n",
    "for file_name, file_path in file_paths:\n",
    "    # 加载 JSON 文件\n",
    "    with open(file_path, 'r') as f:\n",
    "        data = json.load(f)\n",
    "    \n",
    "    # 顺序提取 answers 和 questions，并添加到对应列表中\n",
    "    for item in data:\n",
    "        all_answers.extend(item.get('answers', []))\n",
    "        all_questions.extend(item.get('question', []))\n",
    "\n",
    "# 打印汇总后的标签数量\n",
    "print(f\"总共提取到 {len(all_answers)} 个 answers 标签。\")\n",
    "print(f\"总共提取到 {len(all_questions)} 个 questions 标签。\")\n",
    "print()\n",
    "\n",
    "# 打印汇总后的标签\n",
    "print(\"提取到的所有 answers 标签：\")\n",
    "for answer in all_answers:\n",
    "    print(f\"  - {answer}\")\n",
    "\n",
    "print(\"\\n提取到的所有 questions 标签：\")\n",
    "for question in all_questions:\n",
    "    print(f\"  - {question}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9e1975c-23c4-4aa2-950c-3b5653f78b95",
   "metadata": {},
   "source": [
    "提取每个 answers 和 questions 字符串中的编号，并使用这个编号来匹配数据集中的图片文件名"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20e807c9-903e-4cd5-9460-5af31f4c1b93",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "\n",
    "# 文件路径列表\n",
    "file_paths = [\n",
    "    (\"AAT.json\", r\"./【AiDLab】A100/AAT/label/AAT.json\"),\n",
    "    (\"LAT.json\", r\"./【AiDLab】A100/LAT/label/LAT.json\")\n",
    "]\n",
    "\n",
    "# 用于存储文件名与标签的字典\n",
    "filename_to_label = {}\n",
    "\n",
    "# 正则表达式提取 AAT 和 LAT 格式的编号\n",
    "pattern_aat = re.compile(r'(\\d{3}A\\d{2})')  # AAT 格式，例如 \"001A01\"\n",
    "pattern_lat = re.compile(r'P\\d{8}')         # LAT 格式，例如 \"P00447524\"\n",
    "\n",
    "# 遍历文件路径，加载并提取每个文件中的标签\n",
    "for file_name, file_path in file_paths:\n",
    "    # 加载 JSON 文件\n",
    "    with open(file_path, 'r') as f:\n",
    "        data = json.load(f)\n",
    "    \n",
    "    # 处理 AAT 和 LAT 文件\n",
    "    for item in data:\n",
    "        answers = item.get('answers', [])\n",
    "        questions = item.get('question', [])\n",
    "        \n",
    "        # 合并 answers 和 questions 标签\n",
    "        for label in answers + questions:\n",
    "            # 匹配 AAT 格式编号\n",
    "            match_aat = pattern_aat.search(label)\n",
    "            if match_aat:\n",
    "                file_id = match_aat.group(1)  # 提取编号部分，例如 \"001A01\"\n",
    "                filename_to_label[file_id] = label  # 将编号映射到标签\n",
    "            \n",
    "            # 匹配 LAT 格式编号\n",
    "            match_lat = pattern_lat.search(label)\n",
    "            if match_lat:\n",
    "                file_id = match_lat.group(0)  # 提取编号部分，例如 \"P00447524\"\n",
    "                filename_to_label[file_id] = label  # 将编号映射到标签\n",
    "\n",
    "print(f'字典个数{len(filename_to_label)}')\n",
    "print()\n",
    "# 输出结果示例\n",
    "for filename, label in filename_to_label.items():\n",
    "    print(f\"{filename}.jpg: {label}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45bd5ec4-8d42-4698-b6ff-1ddd6e3f0d48",
   "metadata": {},
   "source": [
    "先统计一下主类别一共有几类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaff88dc-dcdb-476f-8aff-db63fb372085",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# 文件路径列表\n",
    "file_paths = [\n",
    "    (\"AAT.json\", r\"./【AiDLab】A100/AAT/label/AAT.json\"),\n",
    "    (\"LAT.json\", r\"./【AiDLab】A100/LAT/label/LAT.json\")\n",
    "]\n",
    "\n",
    "# 类别映射字典，将标签映射为四大类\n",
    "category_mapping = {\n",
    "    'Shoes': 'shoes',\n",
    "    'Top': 'clothings',\n",
    "    'Pants': 'clothings',\n",
    "    'Skirt': 'clothings',\n",
    "    'Dress': 'clothings',\n",
    "    'Outwear': 'clothings',\n",
    "    'Earing': 'accessories',\n",
    "    'Bracelet': 'accessories',\n",
    "    'Watches': 'accessories',\n",
    "    'Hat': 'accessories',\n",
    "    'Neckline': 'accessories',\n",
    "    'Sunglasses': 'accessories',\n",
    "    'Bags': 'bags'\n",
    "}\n",
    "\n",
    "# 用于存储主类别的集合\n",
    "main_categories = set()\n",
    "\n",
    "# 遍历文件路径，加载并提取主类别\n",
    "for file_name, file_path in file_paths:\n",
    "    # 加载 JSON 文件\n",
    "    with open(file_path, 'r') as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    # 提取 answers 和 questions 中的主类别\n",
    "    for item in data:\n",
    "        answers = item.get('answers', [])\n",
    "        questions = item.get('question', [])\n",
    "        \n",
    "        # 合并 answers 和 questions 标签\n",
    "        for label in answers + questions:\n",
    "            if \"AAT\" in file_name:\n",
    "                # 对 AAT 标签格式进行处理，取主类别部分\n",
    "                main_category = label.split('/')[0].lower()  # 转换为小写\n",
    "            elif \"LAT\" in file_name:\n",
    "                # 对 LAT 标签格式进行处理，取前缀并通过字典映射\n",
    "                main_category = label.split('_')[0]\n",
    "                main_category = category_mapping.get(main_category, None)\n",
    "\n",
    "                # 如果映射成功，将类别转换为小写\n",
    "                if main_category:\n",
    "                    main_category = main_category.lower()\n",
    "\n",
    "            # 如果主类别存在，将其添加到集合中\n",
    "            if main_category:\n",
    "                main_categories.add(main_category)\n",
    "\n",
    "# 将主类别集合转换为有序列表\n",
    "labellist = sorted(list(main_categories))\n",
    "\n",
    "# 输出主类别种类数和类别名称\n",
    "print(f\"主类别总数: {len(main_categories)}\")\n",
    "print(\"主类别列表:\", labellist)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82e363be-4104-4b33-b339-9ccdc42c038b",
   "metadata": {},
   "source": [
    "查看一张图片和标签"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee1c1ccf-ef66-43d7-be33-dc45d6d50429",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset, random_split\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import json\n",
    "import os\n",
    "\n",
    "# 定义图像转换\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  # 调整图像大小\n",
    "    transforms.ToTensor()           # 转换为 Tensor\n",
    "])\n",
    "\n",
    "# 统一的类别映射列表，保证 AAT 和 LAT 数据集的一致性\n",
    "labellist = ['shoes', 'clothing', 'bags', 'accessories']\n",
    "\n",
    "# 类别映射字典，将 LAT 标签映射到四大类\n",
    "category_mapping = {\n",
    "    'Shoes': 'shoes',\n",
    "    'Top': 'clothing',\n",
    "    'Pants': 'clothing',\n",
    "    'Skirt': 'clothing',\n",
    "    'Dress': 'clothing',\n",
    "    'Outwear': 'clothing',\n",
    "    'Earing': 'accessories',\n",
    "    'Bracelet': 'accessories',\n",
    "    'Watches': 'accessories',\n",
    "    'Hat': 'accessories',\n",
    "    'Neckline': 'accessories',\n",
    "    'Sunglasses': 'accessories',\n",
    "    'Bags': 'bags'\n",
    "}\n",
    "\n",
    "# 自定义数据集类，包含 AAT 和 LAT 数据集\n",
    "class FashionDataset(Dataset):\n",
    "    def __init__(self, images_dirs, json_paths, transform=None):\n",
    "        self.images_dirs = images_dirs\n",
    "        self.transform = transform\n",
    "        self.data = []\n",
    "\n",
    "        # 加载 AAT 和 LAT 数据\n",
    "        for images_dir, json_path in zip(images_dirs, json_paths):\n",
    "            with open(json_path, 'r') as f:\n",
    "                json_data = json.load(f)\n",
    "                for item in json_data:\n",
    "                    # 提取 answers 标签和 image ID\n",
    "                    answers = item.get('answers', [])\n",
    "                    if not answers:\n",
    "                        continue\n",
    "                    label_str = answers[0]  # 取第一个作为标签\n",
    "                    \n",
    "                    # 判断是否为 AAT 或 LAT，并提取标签\n",
    "                    if 'AAT' in json_path:\n",
    "                        main_category = label_str.split('/')[0].lower()\n",
    "                    elif 'LAT' in json_path:\n",
    "                        main_category = label_str.split('_')[0]\n",
    "                        main_category = category_mapping.get(main_category, '').lower()\n",
    "\n",
    "                    # 如果主类别存在于映射列表，则添加到数据集中\n",
    "                    if main_category in labellist:\n",
    "                        image_id = label_str.split('_')[-1] + \".jpg\"  # 获取文件名\n",
    "                        img_path = os.path.join(images_dir, image_id)\n",
    "                        self.data.append((img_path, main_category))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_path, main_category = self.data[idx]\n",
    "        label = labellist.index(main_category)  # 将主类别转为索引\n",
    "\n",
    "        # 读取图像\n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        return image, label\n",
    "\n",
    "# 数据加载，处理 AAT 和 LAT 文件夹\n",
    "images_dirs = [\n",
    "    \"./【AiDLab】A100/AAT/image\",  # 修改为 AAT 图片文件夹路径\n",
    "    \"./【AiDLab】A100/LAT/image\"   # 修改为 LAT 图片文件夹路径\n",
    "]\n",
    "json_paths = [\n",
    "    \"./【AiDLab】A100/AAT/label/AAT.json\",  # 修改为 AAT JSON 文件路径\n",
    "    \"./【AiDLab】A100/LAT/label/LAT.json\"   # 修改为 LAT JSON 文件路径\n",
    "]\n",
    "dataset = FashionDataset(images_dirs, json_paths, transform=transform)\n",
    "\n",
    "# 划分数据集为训练集、验证集和测试集，比例为 6:2:2\n",
    "total_size = len(dataset)\n",
    "train_size = int(0.6 * total_size)\n",
    "val_size = int(0.2 * total_size)\n",
    "test_size = total_size - train_size - val_size\n",
    "train_dataset, val_dataset, test_dataset = random_split(dataset, [train_size, val_size, test_size])\n",
    "\n",
    "# 创建 DataLoader\n",
    "trainloader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "valloader = DataLoader(val_dataset, batch_size=64, shuffle=False)\n",
    "testloader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "# 获取一个批次的数据\n",
    "image_batch, label_batch = next(iter(trainloader))\n",
    "\n",
    "# 随机选择一个索引\n",
    "index = random.randint(0, len(image_batch) - 1)\n",
    "\n",
    "# 显示图像和标签\n",
    "imagedemo = image_batch[index]\n",
    "imagedemolabel = label_batch[index]\n",
    "\n",
    "# 转换为可显示格式\n",
    "imagedemo = imagedemo.permute(1, 2, 0)  # 从 (C, H, W) 转换为 (H, W, C)\n",
    "\n",
    "plt.imshow(imagedemo)\n",
    "plt.axis('off')  # 关闭坐标轴\n",
    "\n",
    "print(f'这张图片对应的标签是 {labellist[imagedemolabel]}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62492763-2b52-4d62-9083-c7f5bfd3e350",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 获取一个批次的数据\n",
    "images, labels = next(iter(trainloader))\n",
    "\n",
    "# 打印图像的形状\n",
    "print(f\"图像的形状: {images.shape}\")\n",
    "\n",
    "# 打印标签的内容\n",
    "print(f\"标签的内容: {labels}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c390e175-0887-419c-8cea-0a0f71c9d66b",
   "metadata": {},
   "source": [
    "一个batchsize为64，3个通道（rgb），0123 分别是['shoes', 'clothing', 'bags', 'accessories']的索引"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b90bf2d-59e5-443f-8fcf-f0bf0f1f1c99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义模型的函数\n",
    "def create_model(num_classes):\n",
    "    model = models.resnet18(pretrained=True)\n",
    "    model.fc = nn.Linear(model.fc.in_features, num_classes)  # 输出层与类别数相同\n",
    "    return model\n",
    "\n",
    "# 创建模型\n",
    "model = create_model(len(labellist))\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "\n",
    "# 定义损失函数和优化器\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# 训练循环\n",
    "num_epochs = 20\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for images, labels in trainloader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "\n",
    "    # 计算平均损失\n",
    "    epoch_loss = running_loss / len(trainloader)\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {epoch_loss:.4f}\")\n",
    "\n",
    "    # 验证模型\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in valloader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    val_accuracy = 100 * correct / total\n",
    "    print(f\"Validation Accuracy: {val_accuracy:.2f}%\")\n",
    "\n",
    "# 保存模型\n",
    "torch.save(model.state_dict(), 'resnet_fashion_model.pth')\n",
    "print(\"Model saved as resnet_fashion_model.pth\")\n",
    "\n",
    "# 测试模型\n",
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for images, labels in testloader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "test_accuracy = 100 * correct / total\n",
    "print(f\"Test Accuracy: {test_accuracy:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5abe138-d712-4e64-9e71-39909208bd63",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "from PIL import Image\n",
    "from torchvision import transforms, models\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "\n",
    "# 定义类别映射，将 AAT 和 LAT 的类别统一映射到四大类\n",
    "category_mapping = {\n",
    "    'Shoes': 'shoes',\n",
    "    'Top': 'clothing',\n",
    "    'Pants': 'clothing',\n",
    "    'Skirt': 'clothing',\n",
    "    'Dress': 'clothing',\n",
    "    'Outwear': 'clothing',\n",
    "    'Earing': 'accessories',\n",
    "    'Bracelet': 'accessories',\n",
    "    'Watches': 'accessories',\n",
    "    'Hat': 'accessories',\n",
    "    'Neckline': 'accessories',\n",
    "    'Sunglasses': 'accessories',\n",
    "    'Bags': 'bags',\n",
    "    # AAT 数据集的类别映射（根据您的实际类别进行调整）\n",
    "    'aat_category1': 'clothing',\n",
    "    'aat_category2': 'shoes',\n",
    "    # 添加更多的 AAT 类别映射\n",
    "}\n",
    "\n",
    "class FashionDataset(Dataset):\n",
    "    def __init__(self, dataset, transform=None):\n",
    "        self.images = [data['image'] for data in dataset]\n",
    "        self.labels = [data['label'] for data in dataset]\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = self.images[idx]\n",
    "        label = self.labels[idx]\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, label\n",
    "\n",
    "def create_resnet18_model(num_classes):\n",
    "    model = models.resnet18(pretrained=True)\n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = True\n",
    "    num_ftrs = model.fc.in_features\n",
    "    model.fc = nn.Linear(num_ftrs, num_classes)\n",
    "    return model\n",
    "\n",
    "def train_model(model, train_loader, val_loader, criterion, optimizer, device, scheduler=None, num_epochs=50, patience=5):\n",
    "    best_model_wts = model.state_dict()\n",
    "    best_acc = 0.0\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    train_accuracies = []\n",
    "    val_accuracies = []\n",
    "    early_stopping_counter = 0\n",
    "    best_val_loss = float('inf')\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()\n",
    "                data_loader = train_loader\n",
    "            else:\n",
    "                model.eval()\n",
    "                data_loader = val_loader\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            for inputs, labels in data_loader:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "                optimizer.zero_grad()\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    loss = criterion(outputs, labels)\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "            epoch_loss = running_loss / len(data_loader.dataset)\n",
    "            epoch_acc = running_corrects.double() / len(data_loader.dataset)\n",
    "            if phase == 'train':\n",
    "                train_losses.append(epoch_loss)\n",
    "                train_accuracies.append(epoch_acc.item())\n",
    "            else:\n",
    "                val_losses.append(epoch_loss)\n",
    "                val_accuracies.append(epoch_acc.item())\n",
    "                if scheduler is not None:\n",
    "                    scheduler.step(epoch_loss)\n",
    "                if epoch_loss < best_val_loss:\n",
    "                    best_val_loss = epoch_loss\n",
    "                    early_stopping_counter = 0\n",
    "                    best_model_wts = model.state_dict()\n",
    "                else:\n",
    "                    early_stopping_counter += 1\n",
    "                    if early_stopping_counter >= patience:\n",
    "                        model.load_state_dict(best_model_wts)\n",
    "                        plot_training_curves(train_losses, val_losses, train_accuracies, val_accuracies)\n",
    "                        return model\n",
    "\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    plot_training_curves(train_losses, val_losses, train_accuracies, val_accuracies)\n",
    "    return model\n",
    "\n",
    "def plot_training_curves(train_losses, val_losses, train_accuracies, val_accuracies):\n",
    "    epochs = range(1, len(train_losses) + 1)\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(epochs, train_losses, 'bo-', label='Training Loss')\n",
    "    plt.plot(epochs, val_losses, 'ro-', label='Validation Loss')\n",
    "    plt.title('Training and Validation Loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(epochs, train_accuracies, 'bo-', label='Training Accuracy')\n",
    "    plt.plot(epochs, val_accuracies, 'ro-', label='Validation Accuracy')\n",
    "    plt.title('Training and Validation Accuracy')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def test_model(model, test_loader, device):\n",
    "    model.eval()\n",
    "    running_corrects = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            running_corrects += torch.sum(preds == labels.data)\n",
    "    total = len(test_loader.dataset)\n",
    "    acc = running_corrects.double() / total\n",
    "    print(f'Test Accuracy: {acc:.4f}')\n",
    "\n",
    "def evaluate_model(model, test_loader, device, class_names):\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "    print(\"Classification Report:\")\n",
    "    print(classification_report(all_labels, all_preds, target_names=class_names))\n",
    "    cm = confusion_matrix(all_labels, all_preds)\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(class_names))\n",
    "    plt.xticks(tick_marks, class_names, rotation=45)\n",
    "    plt.yticks(tick_marks, class_names)\n",
    "    thresh = cm.max() / 2.\n",
    "    for i in range(len(class_names)):\n",
    "        for j in range(len(class_names)):\n",
    "            plt.text(j, i, format(cm[i, j], 'd'),\n",
    "                     horizontalalignment=\"center\",\n",
    "                     color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "    plt.ylabel('True Label')\n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def predict(model, image_path, device, data_transforms, class_names):\n",
    "    model.eval()\n",
    "    image = Image.open(image_path).convert('RGB')\n",
    "    image = data_transforms(image).unsqueeze(0)\n",
    "    image = image.to(device)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(image)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "    predicted_class = class_names[preds.item()]\n",
    "    return predicted_class\n",
    "\n",
    "def load_dataset(json_paths, image_dirs):\n",
    "    dataset = []\n",
    "    for json_path, image_dir in zip(json_paths, image_dirs):\n",
    "        with open(json_path, 'r') as f:\n",
    "            data = json.load(f)\n",
    "        all_items = []\n",
    "        for entry in data:\n",
    "            all_items.extend(entry.get('question', []))\n",
    "            all_items.extend(entry.get('answers', []))\n",
    "        items = []\n",
    "        for item in all_items:\n",
    "            if 'AAT' in json_path:\n",
    "                # 处理 AAT 数据集的标签格式\n",
    "                category = item.split('/')[0]\n",
    "                id_ = item.split('/')[-1]\n",
    "                id_ = os.path.splitext(id_)[0]  # 去掉文件扩展名\n",
    "            elif 'LAT' in json_path:\n",
    "                # 处理 LAT 数据集的标签格式\n",
    "                category, id_ = item.split('_')\n",
    "            else:\n",
    "                continue  # 如果有其他数据集，请根据其格式添加处理逻辑\n",
    "            items.append({'category': category, 'id': id_})\n",
    "        unique_items = { (item['category'], item['id']) for item in items }\n",
    "        unique_items = [ {'category': cat, 'id': id_} for cat, id_ in unique_items ]\n",
    "        for item in unique_items:\n",
    "            category = item['category']\n",
    "            id_ = item['id']\n",
    "            label = category_mapping.get(category)\n",
    "            if label is None:\n",
    "                continue\n",
    "            image_path = os.path.join(image_dir, f\"{id_}.jpg\")\n",
    "            if not os.path.exists(image_path):\n",
    "                continue\n",
    "            image = Image.open(image_path).convert('RGB')\n",
    "            dataset.append({'image': image, 'label': label})\n",
    "    return dataset\n",
    "\n",
    "def main():\n",
    "    # 数据集的 JSON 文件和对应的图像目录\n",
    "    json_paths = [\n",
    "        './【AiDLab】A100/LAT/label/LAT.json',\n",
    "        './【AiDLab】A100/AAT/label/AAT.json',\n",
    "        # 添加更多数据集的 JSON 文件路径\n",
    "    ]\n",
    "    image_dirs = [\n",
    "        './【AiDLab】A100/LAT/image',\n",
    "        './【AiDLab】A100/AAT/image',\n",
    "        # 添加更多数据集的图像目录\n",
    "    ]\n",
    "\n",
    "    # 加载并合并多个数据集\n",
    "    dataset = load_dataset(json_paths, image_dirs)\n",
    "\n",
    "    # 标签编码\n",
    "    labels = [data['label'] for data in dataset]\n",
    "    label_encoder = LabelEncoder()\n",
    "    encoded_labels = label_encoder.fit_transform(labels)\n",
    "    class_names = label_encoder.classes_\n",
    "    for idx, data_item in enumerate(dataset):\n",
    "        data_item['label'] = encoded_labels[idx]\n",
    "\n",
    "    # 数据增强和归一化\n",
    "    data_transforms = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.RandomRotation(10),\n",
    "        transforms.RandomResizedCrop(224, scale=(0.8, 1.0)),\n",
    "        transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.2),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ])\n",
    "\n",
    "    # 创建数据集和数据加载器\n",
    "    full_dataset = FashionDataset(dataset, transform=data_transforms)\n",
    "    train_size = int(0.6 * len(full_dataset))\n",
    "    val_size = int(0.2 * len(full_dataset))\n",
    "    test_size = len(full_dataset) - train_size - val_size\n",
    "    train_dataset, val_dataset, test_dataset = random_split(full_dataset, [train_size, val_size, test_size])\n",
    "\n",
    "    batch_size = 8\n",
    "    num_workers = 0\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=num_workers)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=num_workers)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=num_workers)\n",
    "\n",
    "    # 创建和训练模型\n",
    "    num_classes = len(class_names)\n",
    "    model = create_resnet18_model(num_classes=num_classes)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=1e-5)\n",
    "    scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=3, verbose=True)\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "    model = train_model(model, train_loader, val_loader, criterion, optimizer, device, scheduler=scheduler, num_epochs=50, patience=5)\n",
    "\n",
    "    # 测试和评估模型\n",
    "    test_model(model, test_loader, device)\n",
    "    evaluate_model(model, test_loader, device, class_names)\n",
    "\n",
    "    # 进行预测\n",
    "    while True:\n",
    "        image_path = input(\"请输入要预测的图像路径（输入'exit'退出）：\")\n",
    "        if image_path.lower() == 'exit':\n",
    "            break\n",
    "        if not os.path.exists(image_path):\n",
    "            print(\"图像路径不存在，请重新输入。\")\n",
    "            continue\n",
    "        predicted_class = predict(model, image_path, device, data_transforms, class_names)\n",
    "        print(f\"预测的类别是：{predicted_class}\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f36e68b5-f8d6-4ccd-bb15-62415d2f8615",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c59b73b1-67b6-434f-b6c4-0a996ec17361",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
